2.3
--------------------
First we have set epsilon fixed to 0.01 and gradually decrease M from 8 to 2, and we have seen
that classification rate has decreased as well. With parameters M = 8 and epsilon = 0.01, we
were able to achieve a constant perfect score with all 15 correct. As M becomes 2 we observed
that only 12 - 14 were able to be classified correctly and it's somewhat less stable than M = 8.

In terms of eplison, we found it somewhat less relevant to the classification rate. As we set
M = 8, most of the cases we can still achieve a perfect score. But it wasn's completely irrelevant,
as we increase the value of eplison, the results we get become less stable compare to a smaller
epsilon.

When we remove all irrelevant 15 speakers as we calculate the classification rate, we obeserved a
better result as we set M = 2 and eplilon = 0.9, we saw that the results are constantly ranges from
13 to 15 with 14 and 15 much more than 13, this suggests that by reducing the number of irrelevant
speakers to search for, it helps to increase the classification rate.


How might you improve the classication accuracy of the Gaussian mixtures, without adding more
training data?

Use full covariance matrix for the Gaussian Mixture Model instead of diagnoal. In such a case we
can simulate the dependencies among each dimension instead of assuming they are independent to
each other(which they are highly likely not)


When would your classifier decide that a given test utterance comes from none of the trained speaker
models, and how would your classifier come to this decision?

Compute the average likelihood across all utterances with the highest and lowest removed, with the
mean value of the likelihood we can perform a hypothetical z test for every single utterance with
a predefined significant value say alpha equals to 0.05 and thus to tell whether the test utterance
comes from none of the trained speaker.

Can you think of some alternative methods for doing speaker identification that don't use Gaussian
mixtures?

We can use feature extractions to train models for predictions with appropriately selected meaningful
features such as tone, sound speed, vibration rate etc.


3.1
-------------------
With all parameters as default when training the HMM(M = 8, Q = 3, D = 14 and all training data),
we have observed an accuracy of 40.97%(449 correct out of 1096 phonemes).
